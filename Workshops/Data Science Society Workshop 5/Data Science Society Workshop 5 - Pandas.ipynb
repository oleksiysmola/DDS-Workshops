{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Society Workshop 5: Pandas\n",
    "In this workshop we will look at our third Python package Pandas. This in an extremely useful package for data science as its main focus is on storing and operating on data within structures called data frames. \n",
    "#### Importing Pandas\n",
    "Like we did in the last two workshops we start by importing the Pandas package. We will import Numpy and Matplotlib again just in case we need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importing Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure that graphs are displayed within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Series\n",
    "Pandas series are similar to Numpy arrays however the key difference is that we can specify an index for a Pandas series. In most other respects such as when applying numerical operations series behave much like arrays. To generate a series one needs to pass ````pd.Series(x)```` where ````x```` is a list to be converted to a series. One can also pass the argument ````index=y````where ````y```` is a list of the indexes we wish to use for the respective series values. Below are two code cells, the first of which passes no ````index```` argument. This means by default the indexes will be as you expect of a list and Python array ie integers starting from $0$. The second code cell creates a series but passes another list for the ````index```` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Pandas series\n",
    "series = pd.Series([10,20,30,40])\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Pandas series\n",
    "series = pd.Series([10,20,30,40], index=[\"a\",\"b\",\"c\",\"d\"])\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Data Frame?\n",
    "A data frame is essentially a table of data stored as a variable similar to how you store multiple values in an array as a variable. Note the two are **not** the same! Each column in a data frame is represented by a Pandas series. Below we extract data from a **csv (comma seperated variables)** file. Inside the file each column is seperated by a comma as the name suggests. The file is read and the data converted to a data frame which is then displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines df as a data frame without adding an additional index column \n",
    "df = pd.read_csv(\"StarColours.csv\")\n",
    "\n",
    "# Displays the data frame df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the data within the file has been converted into a table. Notice the additional column added to the left of the data frame. This is the index column essentially providing a unique identifier for each row in the table. We can extract the data without this column by specifiying: \n",
    "\n",
    "````df = pd.read_csv(\"StarColours.csv\", index_col=0) ````\n",
    "\n",
    "which tells essentially sets the index column to be coloumn zero (once again Python starts counting from $0$). This is shown in the code cell below. Note that here the index column isn't entirely unique and often its preferable for the index column to consist of unique identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines df as a data frame without adding an additional index column\n",
    "df = pd.read_csv(\"StarColours.csv\", index_col=0)\n",
    "\n",
    "# Displays the data frame df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may recall from the previous workshop I had a code cell to extract data from another file so that you could plot it. Below I've included a snippet of the code. You needn't concern yourself too much with how it works.\n",
    "\n",
    "````\n",
    "molE = open(\"KinEnergy1.txt\",\"r\")\n",
    "\n",
    "molE1 = molE.read().splitlines()\n",
    "\n",
    "l = np.zeros(len(molE1))\n",
    "E = np.zeros(len(molE1))\n",
    "E_average = np.zeros(len(molE1))\n",
    "\n",
    "for i in range(len(molE1)):\n",
    "    l[i] = molE1[i].split()[0]\n",
    "    E[i] = molE1[i].split()[4]\n",
    "    E_average[i] = molE1[i].split()[9]\n",
    "````\n",
    "As you can see this code is significantly longer than the code we used to create our data frame. When files are approapriately formatted often you'll find Pandas a preferable means of extracting data rather than alternatives like the snippet of code above, although sometimes you may have no choice depending on the formatting.\n",
    "#### Delimiter\n",
    "The function ````pd.read_csv()```` assumes by default that your variables are seperated with commas. This is not always the case however. In such cases you'll require a delimiter argument and also potentially an engine argument. The delimiter argument specifies the seperation between columns. By default this is set to a comma. However, the file to be read below contains columns seperated by three spaces. We pass the argument ````delimiter=\"   \"```` to account for the way in which the columns are seperated. This leads to another problem and that is that Pandas is not written entirely in Python. Pandas also makes use of the C engine which doesn't recognise seperators greater than one character. This is fixed by specifying ````engine=\"python\"```` so that Python reads the seperator instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverts data within the specified file into a data frame using the Python engine\n",
    "df = pd.read_csv(\"H2O.csv\", delimiter=\"   \",engine=\"python\")\n",
    "\n",
    "# Displays the data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Frame Slicing \n",
    "Returning to the original data frame we will look at how to select specific columns in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines df as a data frame without adding an additional index column \n",
    "df = pd.read_csv(\"StarColours.csv\")\n",
    "\n",
    "# Displays the data frame df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select a specific column in a data frame we slice in a similar fashion to how we would select a dictionary value. The key here would be the column name as a string. Doing this returns the selected column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the colour column\n",
    "df[\"Color\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can slice further to select a specfic item or set of item in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects seventh item in colour column\n",
    "df[\"Color\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects 4th to 6th items in colour column\n",
    "df[\"Color\"][3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also select multiple columns. Note the need for another set of square brackets as the argument passed is a list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the specified columns\n",
    "df[[\"Color\", \"Main Characteristics\", \"Examples\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathmatical Operations on Data Frame Columns\n",
    "Performing mathmatical operations on data frame columns means the operation will be performed for each element in equivalent positions in the column. Below is what happens when adding the average mass and average radius columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the average mass and radius columns\n",
    "df[\"Average Mass (The Sun = 1)\"] + df[\"Average Radius (The Sun = 1)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining New Columns\n",
    "One can define new columns in a data frame by slicing for a column that doesn't exist and defining items for it. Here we will define a density column below from the average mass and average radius columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a new average density column accordingly\n",
    "df[\"Average Density\"] = (df[\"Average Mass (The Sun = 1)\"]*3)/(4*np.pi*(df[\"Average Radius (The Sun = 1)\"]**3))\n",
    "\n",
    "# Displays the data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame Functions\n",
    "Most functions within Pandas spefically apply to data frames and are called by typing ````df.function()````. Here ````df```` is the data frame and ````function()```` is the function applied to the data frame. Often you can apply these to column slices by typing ````df[\"column name\"].function()````."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.head()\n",
    "This returns the first set of rows in the data frame. By default this is the first five rows. Alternatively you can specify the a number of rows to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns first five rows from the data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns first two rows from data frame\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.tail() \n",
    "Identical to ````df.head()```` except that it the last set of rows is returned instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns last five rows from the data frame\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns last two rows from data frame\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.unique()\n",
    "Returns unique items as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns unique items from the colours column\n",
    "df[\"Color\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.describe()\n",
    "Returns a number of statistical parameters for all colums with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns unique items from the colours row\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you only wanted one of the rows above you could choose only to find the specific row instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the mean of each numerical column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.set_index\n",
    "If I already have a data frame and want to select an index then I can use this function. I pass the column name as the argument. Additionally, writing ````inplace=True```` as an argument means the data frame will be redefined with this new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Replaces the index column for df with the \"Color\" column\n",
    "df.set_index(\"Color\", inplace=True)\n",
    "\n",
    "# Displays data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.loc\n",
    "If you want to select certain rows based on specified conditions then you can use ````df.loc````. This function requires is a bit unlike those you've seen before as it can be used to pass conditional statements. For instance, ````df.loc[df[\"columnname\"] > x]```` will pass return all rows with a values greater than ````x```` for the column labelled \"columnname\". Equally, one could look only for rows with values equal to a particular value. One could use the other comparison operators mentioned in the second workshop on logic. Below are two examples, the first of which searches for rows with values greater than $1$ in the \"Average Mass (The Sun = 1)\" column while the second searches for rows with \"Rigel  Spica\" as the string in the \"Examples\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Returns all rows with values greater than one for the average mass column\n",
    "df.loc[df[\"Average Mass (The Sun = 1)\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns all rows with \"Rigel  Spica\" in the \"Examples\" column\n",
    "df.loc[df[\"Examples\"] == \"Rigel  Spica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Columns to Arrays, Lists and Dictionaries\n",
    "Using ````df.values````,````df.tolist()```` and ````df.to_dict()```` columns can be converted into arrays, lists and dictionaries respectively. When converting to a dictionary the index column provides the key for each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Converts the column to an array\n",
    "df[\"Examples\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts column to a list\n",
    "df[\"Examples\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts column to a dictionary\n",
    "df[\"Examples\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping a Row or Column\n",
    "Using ````df.drop```` it is possible to drop a row or column from a data frame. The first argument requires the row index or column name. This can instead be a list of indexes or column names if you want to drop multiple at the same time. The second argument determines whether you are removing a row or column. Using ````axis=0```` will drop the row with the specified index while ````axis=1```` will drop the specified column. Writing ````inplace=True```` redefines your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the row with \"Red\" as its index\n",
    "df.drop(\"Red\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops rows with \"Red\" and \"Blue\" as their index\n",
    "df.drop([\"Red\",\"Blue\"],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drops the \"Average Density\" column\n",
    "df.drop(\"Average Density\",axis=1,inplace=True)\n",
    "\n",
    "# Displays data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Functions\n",
    "With Pandas like its possible to apply these functions one after the other. A generic example would look something like ````df.function1().function2()```` where ````function1()```` is the first function and ````function2()```` is the second function. Here we will drop two columns at once using the drop function twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drops the main characteristics and examples column\n",
    "df.drop(\"Main Characteristics\",axis=1).drop(\"Examples\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Dataframes\n",
    "Using ````df1.append(df2)```` you can merge two similar data frames together. Provided they have similar columns,\n",
    "this will attach ````df2```` to the bottom of ````df1````. Here we append a data frame to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins the data frame df with itself\n",
    "df.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data Frames\n",
    "Other than reading a file there are other ways in which one can generate data frames.\n",
    "#### pd.DataFrame\n",
    "This allows you to create a data frame in two ways. Note the capitalisation of D and F here is required.\n",
    "##### Passing Dictionaries\n",
    "You can pass dictionaries as arguments. The keys specify the column names and the values specify the items within the columns. Typically you'll pass a list for the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''I'm interested to hear what you make of choosing to put this function towards the end rather\n",
    "than at the start. To me it made sense for them to know what a data frame is first before using\n",
    "this function.'''\n",
    "\n",
    "# Defines a Dictionary \n",
    "x = {\n",
    "    \"column a\": [\"a1\",\"a2\"],\n",
    "    \"column b\": [\"b1\",'b2'],\n",
    "        }\n",
    "\n",
    "# Generates a data frame from dictionary x\n",
    "df = pd.DataFrame(x)\n",
    "\n",
    "# Displays data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passing Lists\n",
    "Alternatively, you can generate a data frame by passing lists. Unlike with dictionaries this approach creates the rows with the column names to be specified afterwards. You pass a list containting a number of lists. Each list within the bigger list will determine each row. The columns are then specified by the second argument ````columns=[\"column a\", column b\"]```` where the input is a list of strings that determine the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a set of lists\n",
    "x = [\"a1\", \"b1\"]\n",
    "y = [\"a2\", \"b2\"]\n",
    "\n",
    "# Combines the two lists into a list containing the lists x and y\n",
    "z = [x,y]\n",
    "\n",
    "# Generates a data frame from the lists x and y\n",
    "df = pd.DataFrame(z,columns=[\"column a\", \"column b\"])\n",
    "\n",
    "# Displays data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pd.read_html\n",
    "In addition to being able to read data frames from files Pandas can also convert tables on websites into data frames. This requires you to pass the URL containing the desired table as a string. In addition you'll likely need a match argument. Passing ````match=\"keyword\"```` means that Pandas will try to convert only the tables with the ````\"keyword\"```` string into data frames. In the code cell below we attempt to convert a table of conductivities from https://en.wikipedia.org/wiki/Electrical_resistivity_and_conductivity into a data frame. There are multiple tables so we pass the ````match=\"coefficient\"```` argument. It is important to note that the output for this function is a list of data frames not a data frame. Here to display the data frame the line ````df = df[0]```` was needed before it could be displayed. Another problem is that some websites block this feature so you won't be able to use this function to convert those tables into data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts conductivity table from Wikipedia into a data frame\n",
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/Electrical_resistivity_and_conductivity\",match=\"coefficient\")\n",
    "\n",
    "# Displays data frame\n",
    "df = df[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN Variables\n",
    "You may have noticed that our latest data frame has a few NaN values appearing. These stand for \"Not a Number\" and are invalid entries which you'll likely want to eliminate when performing any data analysis.\n",
    "#### df.dropna()\n",
    "A brute force way of dealing with NaN variables is to use this function. This essentially removes all rows containing a NaN variable. Passing ````inplace=True```` as an argument redefines the data frame as one with all rows containing NaN removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops all rows containing NaN variables.\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, passing ````axis=1```` will eliminate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops all columns containing NaN variables.\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.fillna\n",
    "When we used ````df.dropna()```` above all rows with NaN data were removed. This can be a problem because we are losing information from the other columns that don't have NaN data. A way of dealing with this is to use ````df.fillna(x)```` instead. Here, instead of removing rows we replace any NaN with whatever ````x```` is. Typically this would be chosen to be some extreme value that would be recognised by an algorithm as an outlier. Again the argument ````inplace=True```` can be used to redefine the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces NaN variables with -99999999\n",
    "df.fillna(-99999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data Frames to Files\n",
    "Just as we can read a file and turn the data within into a data frame, we can also convert data within data frames to files. \n",
    "#### df.to_csv \n",
    "To generate a csv file from a data frame simple write the line ````df.to_csv(\"filename.csv\")```` where ````df```` is the variable the data frame is defined as and ````\"filename.csv\"```` is the name of the csv file that will be generated. We often pass an additional argument ````index=False````. This removes the index column when converting to the file. Often this column will be unesserary and meaningless, only serving to take up space. When reading the file an index column is typically generated anyway so storing the index column isn't necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts data frame into a csv file without an index column\n",
    "df.to_csv(\"conductivities.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Types of File\n",
    "Other commands can produce other types of files from data frames. One example of this is ````df.to_excel(\"filename.xlsx\")```` which creates an Excel file with the name ````filename.xlsx````. One can equally create a data frame from such a file. The equivalent command for the Excel file for this is ````pd.read_excel(\"filename.xlsx\")````."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1) StarColours.csv file data obtained from: https://www.enchantedlearning.com/subjects/astronomy/stars/startypes.shtml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
