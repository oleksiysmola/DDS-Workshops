{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Society Workshop 8 - Support Vector Machine (Solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Ph Recognition\n",
    "The \"ph-recognition.csv\" data set consists of three colour columns (all numerical) indicating how strongly that colour features in a particular Ph measurement. The \"label\" column indicates the resulting Ph value for that set of colours. There is also a \"test?\" column that indicates whether a particular row is allocated for testing. The entry in this column will be ````True```` if this is the case and ````False```` if it's intended for the training set. Split the training as specified by the \"test?\" column. Using a support vector machine algorithm achieve a score of $0.7$ when using ````clf.score````. Hint: think of what arguments can be varied and play around with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL\n",
    "# Generating data frame from csv\n",
    "df = pd.read_csv(\"ph-recognition.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL\n",
    "# Training data\n",
    "X_train = df.drop(\"label\",axis=1).loc[df[\"test?\"] == False].drop(\"test?\",axis=1)\n",
    "y_train = df.loc[df[\"test?\"] == False].drop(\"test?\",axis=1)[\"label\"]\n",
    "\n",
    "# Test data\n",
    "X_test = df.drop(\"label\",axis=1).loc[df[\"test?\"] == True].drop(\"test?\",axis=1)\n",
    "y_test = df.loc[df[\"test?\"] == True].drop(\"test?\",axis=1)[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL\n",
    "# Selecting a support vector machine with a linear kernel as the classifier\n",
    "clf = svm.SVC(gamma=\"auto\",kernel=\"linear\")\n",
    "\n",
    "# Training the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Scoring the classifier\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Travel Insurance Claims\n",
    "The \"travel-insurance.zip\" file contains information on travel insurance claims. Considering only the numerical columns use a support vector machine to build a model that predicts the likelyhood someone claims out on travel insurance. Score your model and use ````train_test_split```` to split into test and training sets. Training for this data set may take a while but all you should need in your ````svm.SVC```` arguments is ````gamma='auto'````."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL\n",
    "# Generating data frame \n",
    "df = pd.read_csv(\"travel-insurance.zip\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL\n",
    "# Independent variables\n",
    "X = df[[\"Duration\",\"Age\",\"Net Sales\",\"Commision (in value)\"]]\n",
    "\n",
    "# Dependent variable\n",
    "y = df[\"Claim\"]\n",
    "\n",
    "# Splitting into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL\n",
    "# Selecting a support vector machine for the classifier\n",
    "clf = svm.SVC(gamma=\"auto\")\n",
    "\n",
    "# Training\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Scoring\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model should return a return a seemingly solid score somewhere in the high $0.9$s. However, consider why this score might not be reflective of your models ability to make predictions. Hint: Consider the entries in the \"Claim\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOLUTION CODE CELL \n",
    "# Number of \"Yes\" claims over total number of claim entries\n",
    "len(df.loc[df[\"Claim\"] == \"Yes\"])/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a tiny fraction of our claims column consists of \"Yes\" entries. This means that are classifier has only really been exposed to the \"No\" claims to any significant degree. It is therefore only natural that it would guess \"No\". Since the column consists mainly of \"No\" anyway such a guess being correct is highly likely so our algorithm doesn't provide much insight into this data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] ph-recognition.csv: https://www.kaggle.com/robjan/ph-recognition\n",
    "\n",
    "[2] travel-insurance.zip: https://www.kaggle.com/mhdzahier/travel-insurance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
